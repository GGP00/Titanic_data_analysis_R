---
title: "PRA2 - Tipología y ciclo de vida de datos"
graphics: yes
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---
<br><br>
<center> <h3> _Alumnos: Omar Mendo Mesa y Guzmán Gómez Pérez _  </h3> </center>
<br><br>


## Índice


1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende
responder?

2. Integración y selección de los datos de interés a analizar.

3. Limpieza de los datos.

3.1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno
de estos casos?

3.2. Identificación y tratamiento de valores extremos.

4. Análisis de los datos.

4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación
de los análisis a aplicar).

4.2. Comprobación de la normalidad y homogeneidad de la varianza.

4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos. En función
de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis,
correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis
diferentes.

5. Representación de los resultados a partir de tablas y gráficas.

6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las
conclusiones? ¿Los resultados permiten responder al problema?


<br><br>

#### 1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende

Este conjunto de datos contiene la información de los pasajeros del Titanic, aquel mítico ferri que naufragó el 15 de abril de 1912, durante su viaje inaugural, después de chocar con un iceberg. Desafortunadamente, murieron 1502 de los 2224 pasajeros y la tripulaciónm debido a la escasez de botes salvavidas y las frias temperaturas del oceano.

Este documento estudia, a través de las herramientas de integración  si existió algún patrón entre los afortundados supervivientes.

__1.1 Carga del dataset:__

```{r}
#getwd()
setwd("/Users/omendom/Desktop/Máster/Tipología y ciclo de vida de los datos/PRA2/Titanic_data_analysis_R/data")
train_df <- read.csv(file="train.csv",head=TRUE,sep=",")
test_df <- read.csv(file="test.csv",head=TRUE,sep=",")

head(train_df,11)
```

__1.2 Descripción de atributos:__

__Embarked__: Puerto de embarcación:

* C = Cherbourg.
* Q = Queenstown.
* S = Southampton

__Cabin__: Nº de cabina.

__Fare__: Tarifa del pasajero.

__Ticket__: Número (Id) del ticket de embarcación.

__Sex__: Género del tripulante.

* 1 si es hombre.
* 0 si es mujer.

__Survival__: Categórica. Potencial etiqueta supervisada de los modelos regresivo:

* 1 si sobrevivió
* 0 si no sobrevivió

__pclass__: Categórica. Aproximación del estado socio-económico (ticket que pagaron para el viaje):

* 1st = Upper
* 2nd = Middle
* 3rd = Lower

__age__: Numérico. Fraccional en caso de ser inferior a 1.

__sibsp__: Categórica.  Nº de  parientes directos (horizontal): de tipo hermanos, hermanastros o esposos (marido o mujer).

__parch__: Categórica. Nº de  parientes directos (vertical); de tipo padre/madre, hijos, hijastros o nietos.

* 0 si el niño viajaba con una cuidadora.

<br><br>

### 2. Integración y selección de los datos de interés a analizar.__

__2.1 Exploración del tipado de los atributos:__

```{r}
str(train_df)
```

Algunos de los datos deberían ser categóricos y no numéricos, por ejemplo:

```{r}
train_df$Survived <- as.factor(train_df$Survived)
train_df$Pclass <- as.factor(train_df$Pclass)
train_df$SibSp <- as.factor(train_df$SibSp)
train_df$Parch <- as.factor(train_df$Parch)
```

Esto se debe a que sus valores son representativos de subgrupos y no de una magnitud numérica medible.

Y otros, son categóricos y deberían ser caracteres (string).

Los valores del atributo Cabin, están compuestos por combinaciones de caracteres y números, contienen cierto orden del que podría extraerse información, ya que este puede abstraer la distribución (localización) de las cabinas en zonas del barco.

```{r}
train_df$Cabin <- as.character(train_df$Cabin)
```

La distribución y el tipado final quedaría del siguiente modo:
 
```{r}
str(train_df)
```

Terminamos con un resumen de los indicadores estadísticos de cada atributo; cuartiles, media, mediana, maximo y minimo para los numéricos. Distribución de valores para los factores. Cantidad de observaciones para los caracteres.

```{r}
summary(train_df)
```

Podemos sacar conclusiones de interés, como:

* Había 263 hombres más que mujeres (lo cual probablemente repercuta en las regresiones al asumir que el hombre tenía más probabilidades de no sobrevivir).
* La edad media de los tripulantes era de 30 años aproximadamente. El más anciano tenía 80 años y el más jóven tenía 4 meses y medio. El 50% de la población oscilaba entre los 20 y los 38 años.
* 

<br><br>

### 3. Limpieza de los datos.__

__3.1. ¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?__

Investigamos ahora qué cantidad de valores asuentes o vacíos hay en cada atributo.

Para el único atributo de tipo String, deberemos considerar los caracteres vacíos como valores ausentes también. En los factores no es necesario puesto que se podrían considerar una categoría más.

```{r}
train_df$Cabin[train_df$Cabin==""] <- NA
train_df$Cabin[train_df$Cabin==" "] <- NA
```


```{r}
sapply(train_df, function(x) sum(is.na(x)))
```

Son demasiados registros como para eliminarlos. Para imputar estos valores se podría aplicar un clustering por k Nearest Neighbourgs, reemplazando el valor nulo por el valor de las observaciones (pasajeros). Por ejemplo, aquellos que tengan un parentesco similar, es muy probable que tengan un rango de edad similar.


```{r}
#install.packages('VIM')
library(VIM)

train_df$Age <- kNN(train_df)$Age
```

El caso de la cabina no tiene sentido inferirlo por clustering. Ya que ningún atributo correlacciona apropiadamente este valor. En cambio, se sustituirá por un valor común, que podrá ser útil en caso de que estos pasajeros sin cabina, guardaran algún tipo de vinculo.

```{r}
train_df$Cabin[is.na(train_df$Cabin)] <- "Sin cabina"
```




__3.2. Identificación y tratamiento de valores extremos.__



Veamos qué valores numéricos marginales puede haber en los atributos numéricos Age y Fare. Estos valores pueden aparecer por errores de inserción o por ser observaciones anómalas; se eliminarán para tratar de conseguir unas regresiones que generalicen lo mejor posible.

```{r}
outlier_values <- boxplot.stats(train_df$Age)$out
boxplot(train_df$Age, main="Age", boxwex=0.1)
mtext(paste("Outliers: ", paste(outlier_values, collapse=", ")), cex=0.6)
train_df <- train_df[-which(train_df$Age %in% outlier_values),] # los eliminamos
```

Los valores extremos se sitúan a partir de los 66 años en adelante.

```{r}
library(ggplot2)
ggplot(train_df, aes(x = Age)) + geom_histogram(aes(y = ..density..), binwidth=2, color='blue', fill="white") + geom_density(color='red')
```

Observamos en el histograma superior que la distribución parece ser gaussiana.


```{r}
outlier_values <- boxplot.stats(train_df$Fare)$out
boxplot(train_df$Fare, main="Fare", boxwex=0.1)
mtext(paste("Outliers: ", paste(outlier_values, collapse=", ")), cex=0.6)
train_df <- train_df[-which(train_df$Fare %in% outlier_values),] # los eliminamos
```


Por lo visto, era extraño que el ticket superara el coste de los 70 dolares. Los costes más altos se deberían o bien a errores o bien a Cabinas con unas condiciones privilegiadas. Y por lo visto, no era raro pasar gratis, ya que el cero lo considera un valor común más.


```{r}
ggplot(train_df, aes(x = Fare)) + geom_histogram(aes(y = ..density..), binwidth=2, color='blue', fill="white") + geom_density(color='red')
```



### 4. Análisis de los datos.

__4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).__

El nombre es prescindible puesto que ya tenemos un identificador ya. Aun así, 
podrían llegar a deducirse información útil como la nacionalidad (aproximada) del pasajero. Pero esta tarea no aplica al alcance de esta tarea.

```{r}
train_df$Name <- NULL
```

Del mismo modo, podríamos asumir que el ticket se trata del identificador del tripulante y que no contiene otro tipo de información deducible o complementaria, más allá del orden de compra del ticket, lo cual, dificilmente interviene en la supervivencia del pasajero. Además, ya tenemos un ID por lo que prescindiremos del atributo.

```{r}
train_df$Ticket <- NULL
```


__4.2. Comprobación de la normalidad y homogeneidad de la varianza.__

Veamos si los atributos numéricos Age y Fare siguen una distribución normal.

Para ambos casos y según el teorema del límite central, al ser el tamaños de la muestras suficientemente grande (> 30), siguen __distirbución normal estándar__.

Ahora aplicaremos el __test de Shapiro__ para confirmar esta distribución:


```{r}
alpha = 0.05
shapiro.test(train_df$Age)$p.value > alpha
```

Age tiene una distribución normal.

```{r}
alpha = 0.05
shapiro.test(train_df$Fare)$p.value > alpha
```

Fare tiene una distribución normal.

Ambos atributos pasan el test al ser los valores de p superiores al del nivel de significacia 0.05.

Por otro lado, utilizamos el gráfico Q-Q, para diagnosticar la desviación de los datos de la muestra en relación con una población normal:

```{r}
qqnorm(train_df$Age)
qqline(train_df$Age)
```


```{r}
qqnorm(train_df$Fare)
qqline(train_df$Fare)
```

Ambos conjuntos de datos cumplen la linealidad de la diagonal (aproximadamente), confirmando el resultado del test Shapiro-Wilk y con ello la normalidad de sus distribuciones.

__4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.__

__Correlaciones:__

Para comenzar con la aplicación de pruebas estadísticas sobre nuestro conjunto de datos, usaremos una **matriz de correlación** para poder observar o seleccionar las variables que sean de mayor interés o que nos arrojen algún resultado esclarecedor de si alguna de las variables descritas en nuestro dataset, infiere sobre la probabilidad de supervivencia.

Para realizar dicha matriz, tenemos que realizar una serie de modificaciones en nuestro conjunto de datos, ya que para poder realizar correlaciones entre múltiples variables, necesitamos que estas sean *numéricas*. Por ello, la variable *Sex* la modificaremos, donde el valor **female** tomará el valor **1** y el valor **male** tomará el valor **0**. A su vez, para esta prueba, descartaremos la variable **Cabin**.

Además, la variable **Embarked** debenmos modificarla de la misma manera que **Sex**, por lo que la modificación de realizará de la siguiente manera:

* Cherbourg(**C**) = 0
* Queenstown(**Q**) = 1
* Southampton(**S**) = 2

```{r}
# Creamos un nuevo conjunto de datos a partir del original (solo para esta prueba)
train_df_corr <- train_df

# Realizamos las modificaciones descritas anteriormente
train_df_corr$Sex[train_df_corr$Sex=='male'] <- 0
train_df_corr$Sex[train_df_corr$Sex=='female'] <- 1

train_df_corr$Embarked[train_df_corr$Embarked=='C'] <- 0
train_df_corr$Embarked[train_df_corr$Embarked=='Q'] <- 1
train_df_corr$Embarked[train_df_corr$Embarked=='S'] <- 2

train_df_corr$Survived <- as.numeric(train_df_corr$Survived)
train_df_corr$Pclass <- as.numeric(train_df_corr$Pclass)
train_df_corr$Sex <- as.numeric(train_df_corr$Sex)
train_df_corr$Age <- as.numeric(train_df_corr$Age)
train_df_corr$SibSp <- as.numeric(train_df_corr$SibSp)
train_df_corr$Parch <- as.numeric(train_df_corr$Parch)
train_df_corr$Fare <- as.numeric(train_df_corr$Fare)
train_df_corr$Embarked <- as.numeric(train_df_corr$Embarked)

train_df_corr$Cabin <- NULL
train_df_corr$PassengerId <- NULL

head(train_df_corr, 10)
```

Una vez realizadas las transformaciones previas a nuestro nuevo conjunto de datos (únicamente para esta prueba), aplicaremos el *test de Spearman* para poder calcular las correlaciones entre pares de variables.

```{r}
# Aplicamos el test de Spearman
corr_res <- cor(train_df_corr, method="spearman")
corr_res
```
A continuación, realizaremos una representación gráfica de nuestra matriz de correlación, donde podremos observar qué variables están correlacionadas con otras.
```{r}
# Aplicamos el test de Spearman
library(corrplot)
corrplot(corr_res, method="color", tl.col = "black")
```

Como podemos observar, hay una clara correlación entre las variables **Sex** y **Survived**, por lo que la probabilidad de sobrevivir a la catástrofe vino dada, en parte, por el sexo.

Además, se observa un grupo de correlación entre diversas variables sobre **Parch** que, como sabemos del análisis previo de nuestro conjunto de datos, viene dado por el número de parientes directos (de tipo vertical, como pueden ser padres, hijos, nietos...)

Como vemos, la variable **Parch** esta correlacionada con la variable **SibSp**, que a simple vista, podemos deducir que, al tratarse de número de parientes directos (tanto en vertical como en horizontal), estas variables van a ir normalmente de la mano para cada pasajero

Así como la variable **Fare**, que esta correlacionada con las variables anteriormente descritas, **SibSp** y **Fare**.


__Contraste de hipótesis:__

* __Hipótesis nula o de partida unilateral (H0):__ el coste medio de los tickets de los supervivientes supera en 6 dolares al coste de los que no sobrevivieron.

* __Hipótesis alternativa  (H1):__ el coste medio de los tickets de los supervivientes es igual o menor a 6 dolares al coste de los que no sobrevivieron.

Confirmamos distribuciones normales de los subconjuntos poblacionales (t-student al ser muestrales).

```{r}
alpha = 0.05
shapiro.test(train_df$Fare[ train_df$Survived==1 ])$p.value > alpha
```

```{r}
alpha = 0.05
shapiro.test(train_df$Fare[ train_df$Survived==0 ])$p.value > alpha
```

Efectivamente, lo son. Por tanto:

```{r}
t.test(train_df$Fare[ train_df$Survived==1 ], train_df$Fare[ train_df$Survived==0 ],alternative="greater", var.equal=FALSE)
```

Se apoya la hipótesis nula de que las tarifas de los supervivientes superaban los 6 dolares a las de los no supervivientes con una tasa de acierto del 95%.


__Regresión logística:__

Al ser la etiqueta supervisada binaria, aplicamos una regresión logística:

```{r}
glm.fit <- lm(as.numeric(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Cabin + Embarked, data = train_df)
summary(glm.fit)
```


Los atributos que más impacto tienen en el resultado de la supervivencia del naufragio son:

* Sexmale: Los hombres tenían una probabilidad muy alta de no sobrevivir, probablemente porque fueron los últimos en entrar a los botes salvavidas, priorizando a mujeres y niños.

* Age: Cuanto mayor eras, menos probabilidades de supervivencia tenías, muy probablemente, por la misma razón que la anteriormente explicada.

* SibSp3, SibSp4, SibSp5: tener muchos familiares a bordo no era una garantía de supervivencia, probablemente, por tener que priorizarles o perder tiempo velando por su supervivencia durante el naufragio.

* Fare: Haber pagado una tarifa alta contribuía en cierta medida a la supervivencia, probablemente vinculado a la relevancia de esas personas y/o a su prioridad en botes salvavidas, incluida en las condiciones de embarque.

* CabinA20, CabinA26, CabinA31 Algunas cabinas fueron afortunadas, lógicamente por su ubicación, pudieron, quizás, llegar antes a los botes salvavidas.



__5. Representación de los resultados a partir de tablas y gráficas.__


Relación entre el género y la supervivencia:

```{r}
ggplot(train_df, aes(Sex, ..count..)) + geom_bar(aes(fill = Survived), position = "dodge")
```

Confirmamos que ser hombres perjudicaba a la supervivencia.

Relación entre el parenteso "horizontal" y la supervivencia:

```{r}
ggplot(train_df, aes(SibSp, ..count..)) + geom_bar(aes(fill = Survived), position = "dodge")
```

Confirmamos que a mayor número de familiares, menor probabilidad de supervivencia.

Relación entre la edad y la supervivencia:

```{r}
boxplot(Age~Survived,
data=train_df,
xlab="Survived",
ylab="Age",
col="orange",
border="brown"
)
```

Confirmamos que los que sobrevivieron eran algo más jóvenes que los que no, sobre los 25 años de media.

Relación entre la tarifa y la supervivencia:

```{r}
boxplot(Fare~Survived,
data=train_df,
xlab="Survived",
ylab="Fare",
col="orange",
border="brown"
)
```

Confirmamos que los que sobrevivieron también tenían tarifas más caras.

__6. Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?__

Una vez realizados todos los pasos anteriores, podemos sacar como conclusiones los resultados obtenidos de las distintas pruebas estadísticas sobre nuestro conjunto de datos que, a través de diversas *tablas* y *gráficas*, podemos ver las distintas variables que influyeron sobre la probabilidad de sobrevivir al hundimiento del Titanic.

Como primer paso, los datos han sido sometidos a un procesamiento para manejar lso casos de ceros o elementos vacíos y valores extremos (*outliers*).

A través de los resultados obtenidos, en este caso, de la matriz de correlación y la regresión logística, podemos observar claramente cuáles eran los patrones que determinaron las probabilidades de sobrevivir de cada pasajero. Como principal resultado, se obtuvo que los **hombres** tenían una alta propabilidad de **no sobrevivir**, marcado por la organización de los botes salvavidas, ya que **las mujeres y niños tenian prioridad** a la hora de embarcar en los botes.

Otro resultado clarificador, es la **edad**, cuanto mayor era un pasajero, mayores probabilidades de **no sobrevivir** tenía, ya sea por la capacidad de reacción, velocidad o capacidad para poder zafarse de los infortunios antes de tener probabilidades de sobrevivir.

Como pudimos ver en la matriz de correlación, las variables que conformaban el **número de parientes directos** (tanto verticales como horizontales) estaban correlacionadas, que, más tarde, pudimos observar de forma gráfica cómo el número de parientes de cada pasajero **influía negativamente en las probabilidades de supervivencia** del mismo, ya que, **a mayor número de parientes en el barco, menor probabilidad de supervivencia**, ya sea por el afán de cada pasajero de encontrar, proteger y poner a salvo a sus parientes.

Otro resultado bastante claro es el que nos arroja la variable **Fare**, tanto en la matriz de correlación como en la regresión logística, ya que el haber pagado una tarifa superior al resto de pasajeros, pudo influir en las probabilidades de sobrevivir, ya que, por ejemplo, un pasajero de clase alta (se presupone que ha pagado una tarifa alta) tuvo mayores facilidades para sobrevivir que una persona que haya pagado la tarifa de menor coste, ya que, tal vez, pudo embarcar antes ese pasajero de alta clase que el que no.

Y, como resultado final que se obtuvo en la regresión logística, es que el número de cabina influyó en las probabilidades de sobrevivir de sus ocupantes, básicamente, por la posición en la que se encontraban en el barco, seguramente, más cerca de los botes.

Antes esta batería de resultados, podemos responder satisfactoriamente que los resultados obtenidos sí responden al problema propuesto al comienzo de este estudio.


## Contribuciones

Contribuciones: Firma

__Investigación previa__: Omar Mendo Mesa y Guzmán Gómez Pérez.

__Redacción de las respuestas__: Omar Mendo Mesa y Guzmán Gómez Pérez.

__Desarrollo código__: Omar Mendo Mesa y Guzmán Gómez Pérez.
